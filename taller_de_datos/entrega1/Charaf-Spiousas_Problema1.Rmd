---
title: "Taller de Análisis de datos - Problema 1"
author: "Jésica Charaf e Ignacio Spiousas"
date: "6 de noviembre de 2023"
output:
  pdf_document:
    extra_dependencies: ["float"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.pos = "H", 
                      out.extra = "")
pacman::p_load(tidyverse, here, glmnet, tidymodels, pls, patchwork, broom, knitr)
theme_set(theme_bw(base_size = 10))
```

# Problema 1-4

Los siguientes datos corresponden a un trabajo para determinar la composición de un conjunto de vasijas de vidrio de un yacimiento arqueológico. Como el análisis espectrométrico es más barato que el análisis químico, se procuró calibrar el primero para que reemplace al segundo. Con este objetivo se tomó una muestra de $n=180$ vasijas, a las que se realizó una espectrometria de rayos X sobre 1920 frecuencias, y también un análisis de laboratorio para determinar el contenido de 13 compuestos químicos, a saber:

$$Na_2O, \; MgO, \; Al_2O_3, \; SiO_2, \; P_2O_5, \; SO_3, \; Cl, \; K_2O, \; CaO, \; MnO, \; Fe_2O_3, \; BaO \; y \; PbO$$

Cada fila del archivo `Vessel_X` es el espectro de una vasija, limitado a las frecuencias $100$ a $400$, pues las demás tienen valores casi nulos. O sea, para cada $i=1,...,n, x(i,j (j=1,..,301))$ es la energía correspondiente a la frecuencia $j$ (en realidad la frecuencia es j+99, pero podemos dejar eso de lado).

Cada fila del archivo `Vessel_Y` tiene los contenidos de los 13 compuestos en esa vasija. Vamos a comparar distintos métodos para predecir el compuesto 4 ($SiO_2$).

Para familiarizarse con los datos, grafique en función de la frecuencia las medias y varianzas de X, y también algunos espectros (o sea, $x(i,j)$ en función de $j$ para algunos $i$). Aplique los métodos que le parecen adecuados para este problema, y encuentre el que muestra menor error de predicción.

Para el estimador que mejor funciona:

-   Grafique los coeficientes (pendientes) en función de la frecuencia.

-   Haga el clásico gráfico de residuos vs. ajustados.

-   Si ve algo llamativo (outliers, residuos con estructura) tome las medidas correctivas que le parezcan adecuadas.

# Resolución

## Análisis exploratorio

Lo primero que vamos a hacer es graficar el contenido de `Vessel_X.txt`, es decir, la energía por banda de frecuencia de cada una de las $180$ vasijas. Esto puede verse en líneas continuas de colores en la figura \ref{fig:inicial} junto con el promedio en línea sólida negra. En la figura pareciera ponerse de manifiesto que las diferencias entre vasijas ocurren a determinadas frecuencias (en las que la amplitud es distinta de cero y hay más diferencia entre las mediciones individuales) y, por lo tanto, resulta esperable que la información contenida en esas bandas de frecuencias sea la que más aporte a la determinación del contenido de $SiO_2$ (aunque bajo condiciones particulares podría no ser el caso).

```{r data_loading, fig.align="center", fig.height = 2.5, fig.width = 4, fig.cap = "An amazing plot"}
data_x <- read_delim(here("taller_de_datos/entrega1/data/Vessel_X.txt"),
                     name_repair = "unique",
                     col_names = FALSE,
                     col_types = cols())

data_y <- read_delim(here("taller_de_datos/entrega1/data/Vessel_Y.txt"),
                     name_repair = "unique",
                     col_names = FALSE,
                     col_types = cols()) %>%
  select(X4) %>%
  rename(Y = X4)
```

```{r fig_inicial, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:inicial}Amplitud en función de las frecuencias. Cada línea de color representa una vasija mientras que la línea negra representa al promedio de las 180 vasijas."}
data_x_long <- data_x %>% 
  mutate(sample = factor(row_number())) %>%
  pivot_longer(cols = 1:last_col(1)) %>%
  rename(X = name) %>%
  mutate(X = parse_number(X) + 99) 

summ_data_x <- data_x_long %>%
  group_by(X) %>%
  summarise(m_value = mean(value),
            sd_value = sd(value))

data_x_long %>%
  ggplot(aes(x = X, y = value)) +
  geom_line(aes(color = sample), alpha = .1) +
  geom_line(data = summ_data_x, aes(x = X, y = m_value), linewidth = 1) +
  labs(x = "Frecuencia", y = "Energía") +
  scale_color_viridis_d() +
  theme_bw() +
  theme(legend.position = "none")
```

Para explorar esta idea un poco más podemos ver en la figura \ref{fig:figSD} la desviación estándar (SD) en función de la banda de frecuencia. En esta figura vemos cuantificada la intuición que generamos en la figura \ref{fig:inicial} de que la variabilidad en las mediciones se concentra en unas pocas bandas de frecuencia.

```{r fig_SD, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:figSD}Desviación estándar en función de la banda de frecuencia."}
summ_data_x %>%
  ggplot(aes(x = X, y = sd_value)) +
  geom_line(linewidth = 1) +
  labs(x = "Frecuencia", y = "SD") +
  theme_bw()
```

Luego, nos interesa ver cómo se distribuye la cantidad de $SiO_2$ en las muestras para ver si esto tiene algún patrón. En la figura \ref{fig:histograma} podemos ver el histograma y la densidad estimada para esta magnitud. En la misma se observa que no pareciera haber valores atípicos y que la distribución es unimodal con una cola pesada a la izquierda (hacia valores más bajos). Esta asimetría podría llegar a influir en el supuesto de normalidad de los errores del modelo a ajustar, más adelante lo evaluaremos.

```{r histograma_y, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:histograma}Histograma y estimación de la densidad de la cantidad de $SiO_2$ en las muestras."}
data_y %>%
  ggplot(aes(x = Y)) +
  geom_histogram(aes(y = after_stat(..density..)), 
                 fill = "steelblue", alpha = 0.5, bins = 30) +
  geom_density(color = "steelblue", linewidth = 1.5) +
  theme_bw() +
  labs(x = "Contenido de SiO2", y = "Densidad") +
  theme(legend.position = "none")
```

Finalmente, y a modo exploratorio, vamos a calcular el coeficiente de correlación entre la amplitud de cada banda de frecuencia y la cantidad de $SiO_2$. De esta forma queremos seguir indagando sobre qué bandas de frecuencia deberían ser más importantes en el modelo de predicción. En la figura \ref{fig:correlaciones} puede verse el valor absoluto del coeficiente de correlación de Pearson en función de la banda de frecuencia. Retomaremos los resultados de esta figura luego de ajustar un modelo.

```{r correlaciones, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:correlaciones} Módulo del coeficiente de correlación de Pearson entre la amplitud de cada frecuencia y la cantidad de $SiO_2$."}
data_xy <- data_x %>%
  bind_cols(data_y)

cor_coef <- rep(NA, 301)
for (i in 1:301) {
  cor_coef[i] <- cor(data_xy[,i], data_xy$Y)
}

data_cor  <- tibble(X = unique(data_x_long$X),
                    r = cor_coef)

data_cor %>%
  ggplot(aes(x = X, y = abs(r))) +
  geom_line(linewidth = 1) +
  labs(x = "Frecuencia", y = "|r|") +
  theme_bw()

```

## Construcción de un modelo predictivo

Como lo que queremos hacer es entrenar un modelo predictivo, la métrica que vamos a utilizar para evaluarlo es el error cuadrático medio (MSE^[Del inglés *Mean Squared Error*.]) calculado a partir de una muestra de *testeo*. Para esto vamos a dividir los datos en dos partes, dejando dos tercios de los datos (120 vasijas) en el set de entrenamiento o *training* y un tercio de los datos (60 vasijas) en el set de validación o *testing*. Para evitar que haya una representación desigual de cantidad de $SiO_2$ en las muestras de entrenamiento y validación, realizaremos esta división estratificada^[Como se trata de una variable numérica, la función estratifica la separación a partir de los cuartiles.] utilizando la función `initial_split` del paquete `tidymodels`. 

Vamos a considerar dos familias de modelos para resolver este problema. Primero exploraremos los modelos lineales con regularización (Ridge, Lasso o Elastic Net) utilizando el paquete `glmnet`. Luego exploraremos modelos basados en regresión de componentes principales (PCR^[Del inglés *Principal Components Regression*.]) utilizando el paquete `pls`.

```{r train_test}
set.seed(1234)
split <- initial_split(data_xy, strata = Y, prop = 2/3)
training <- training(split)
training_x <- training(split) %>% select(-Y)
training_y <- training(split) %>% select(Y)
testing <- testing(split)
testing_x <- testing(split) %>% select(-Y)
testing_y <- testing(split) %>% select(Y)
```

### Modelos lineales con regularización

El primer modelo que vamos a ajustar es un modelo lineal con regularización de Lasso ($\alpha=1$ en `glmnet`). Para esto vamos a utilizar el set de datos de entrenamiento y para encontrar el mejor $\lambda$ consideraremos como criterio el MSE y una validación cruzada con 10 *folds*.

```{r}
set.seed(123)
cvfit <- cvfit <- cv.glmnet(as.matrix(training_x), as.matrix(training_y), type.measure = "mse", nfolds = 10, alpha = 1)
tidied <- tidy(cvfit)

myCoefs <- coef(cvfit, s="lambda.min");

myResults <- tibble(
  Componente  = myCoefs@Dimnames[[1]][ which(myCoefs != 0 ) ], #intercept included
  Coeficiente = myCoefs              [ which(myCoefs != 0 ) ]  #intercept included
)
```


Para la regresión con regularización Lasso el $\lambda$ que minimiza el MSE es `r tidied$lambda[which.min(tidied$estimate)]`, con un valor de MSE de `r tidied$estimate[which.min(tidied$estimate)]`. 

En la figura \ref{fig:coefcorrel} podemos ver que una buena parte de los coeficientes no nulos del modelo se corresponden con variables con alta correlación con Y. Esto es meramente exploratorio ya que para la selección de variables también resulta relevante qué tan correlacionadas están las variables entre sí.

```{r componentes, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:coefcorrel}Módulo del coeficiente de correlación de Pearson entre la amplitud de cada frecuencia y la cantidad de $SiO_2$. En forma de banda vertical roja aparecen las frecuencias para las que el coeficiente ajustado por el modelo con regularización Lasso es no nulo."}
data_cor %>%
  ggplot(aes(x = X, y = abs(r))) +
  geom_vline(xintercept = parse_number(myResults[2:37,]$Componente)+99, color = "red", linewidth = 2, alpha = .5)+
  geom_line(linewidth = 1) +
  labs(x = "Frecuencia", y = "|r|") +
  theme_bw()

```
#### Buscando los mejores parámetros $\lambda$ y $\alpha$:

Para seguir, además de buscar el mejor $\lambda$, realizaremos una búsqueda considerando una grilla para el parámetro $\alpha$. Este parámetro es el responsable de convertir el modelo de Ridge ($\alpha = 0$) a Lasso ($\alpha = 1$) pasando por Elastic Net (con valores de $\alpha$ intermedios). Haremos la búsqueda para una grilla de valores entre $0$ y $1$ con paso de $0.01$.

```{r glmnet, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:MSEalpha}MSE para modelos de glmnet en función de $\\alpha$ (de Ridge a Lasso) para el mejor $\\lambda$ obtenido a partir de validación cruzada con 10 folds. El panel b muestra un zoom para valores de $\\alpha$ de 0.5 a 1"}
alphas <- seq(0,1,.01)

errors <- rep(NA, length(alphas))
SEs <- rep(NA, length(alphas))
lambdas <- rep(NA, length(alphas))
nzeros<- rep(NA, length(alphas))

for (i in 1:length(alphas)) {
  set.seed(123)
  cvfit <- cv.glmnet(as.matrix(training_x), as.matrix(training_y), type.measure = "mse", nfolds = 10, alpha = alphas[i])
  tidied <- tidy(cvfit)
  errors[i] <-tidied$estimate[which.min(tidied$estimate)]
  SEs[i] <- tidied$std.error[which.min(tidied$estimate)]
  lambdas[i] <- tidied$lambda[which.min(tidied$estimate)]
  nzeros[i] <- tidied$nzero[which.min(tidied$estimate)]
}

results <- tibble(alphas, errors, SEs)

p1 <- results %>%
  ggplot(aes(x = alphas,
             y = errors)) +
  geom_line(linewidth = 1) +
  labs(x = "Alpha", y = "MSE", subtitle = "MSE en función de alpha") +
  geom_ribbon(aes(ymin = errors-SEs, ymax = errors+SEs), alpha = .3) +
  theme_bw()

p2 <- results %>%
  ggplot(aes(x = alphas,
             y = errors)) +
  geom_line(linewidth = 1) +
  geom_ribbon(aes(ymin = errors-SEs, ymax = errors+SEs), alpha = .3) +
  labs(x = "Alpha", y = "MSE", subtitle = "Zoom de alpha 0.5 a 1") +
  xlim(c(0.5, 1)) +
  ylim(c(0.4, .9)) +
  theme_bw()

p1 + p2 + plot_annotation(tag_levels = 'a')
```

En la figura \ref{fig:MSEalpha} representamos, en función del $\alpha$, el valor del MSE correspondiente al $\lambda$ óptimo obtenido por Cross-Validation con 10 folds. Puede verse que el MSE disminuye monótonamente con el $\alpha$, llegando a un mínimo de `r round(min(errors), digits = 3)` para $\alpha=1$. Es decir, la regresión con regularización Lasso es la más conveniente. Para este valor de $\alpha$, el mínimo error se obtuvo para un $\lambda$ de `r round(lambdas[which.min(errors)], digits = 2)` con un número de coeficientes no nulos igual a `r nzeros[which.min(errors)]`.

### Regresión de componentes principales

Otro enfoque que exploramos para abordar el problema es el de reducción de la dimensión. Consideramos el método PCR que consiste en ajustar un modelo de regresión lineal utilizando como variables predictoras un sobconjunto de las componentes obtenidas a partir del análisis de componentes principales (PCA^[Del inglés *Principal Components Analysis*.]). De esta manera, se reduce la cantidad de variables predictoras del modelo.

Para implementar este método utilizamos la función `pcr` de la librería `pls`. Esta función calcula las componentes principales y ajusta el modelo de regresión lineal con la cantidad de componentes que se desee. Para elegir la cantidad de componentes usamos validación cruzada sobre la muestra de entrenamiento, separando en $10$ folds y buscando el número que minimice el error de predicción. En la figura \ref{fig:MSEPCR} se muestra un gráfico con los resultados del MSE obtenido por validación cruzada en función de la cantidad de componentes.

```{r PCR, warning = FALSE}
#pcr
set.seed(1234)
modelo_pcr <- pcr(formula= Y ~ .,data = training, scale. = TRUE, validation = "CV")
modelo_pcr_CV <- MSEP(modelo_pcr, estimate= "CV")
cv_min_pcr <- min(modelo_pcr_CV$val)
```

```{r PCR_plot, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:MSEPCR}MSE obtenido por validación cruzada en función de la cantidad de componentes."}

modelo_pcr_tbl <- tibble(componentes = 1:length(modelo_pcr_CV$val),
                     MSE = modelo_pcr_CV$val[1:length(modelo_pcr_CV$val)])
                                             
p1 <- modelo_pcr_tbl  %>% ggplot(aes(x = componentes,
                                     y = MSE)) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = which.min(modelo_pcr_tbl$MSE), color = "red", linetype = "dashed") +
  labs(x = "Número de componentes", y = "MSE", subtitle = "Todas las componentes")+
  theme(plot.subtitle=element_text(hjust=0.5))

p2 <- modelo_pcr_tbl  %>% ggplot(aes(x = componentes,
                                     y = MSE)) +
  geom_line(linewidth = 1) +
  xlim(c(60, 90)) +
  ylim(c(.3, .4)) +
  geom_vline(xintercept = which.min(modelo_pcr_tbl$MSE), color = "red", linetype = "dashed") +
  labs(x = "Número de componentes", y = "MSE", subtitle = "Zoom de 60 a 90 componentes") +
  theme(plot.subtitle=element_text(hjust=0.5))

p1 + p2 + plot_annotation(tag_levels = 'a')
  
```

El óptimo se encuentra en `r which.min(modelo_pcr_tbl$MSE)` componentes y el valor obtenido para el error de predicción por validación cruzada sobre la muestra de entrenamiento es `r round(modelo_pcr_tbl$MSE[which.min(modelo_pcr_tbl$MSE)], digits = 3)`.

## Elección del modelo predictivo

A partir del análisis realizado, vemos que el método de PCR ajustado con `r which.min(modelo_pcr_tbl$MSE)` componentes es el que muestra menor MSE con un valor de `r round(modelo_pcr_tbl$MSE[which.min(modelo_pcr_tbl$MSE)], digits = 3)`, en comparación con el óptimo obtenido para los métodos de regularización que nos dió `r round(min(errors), digits = 3)`. De esta manera, consideramos que lo más conveniente es utilizar el modelo ajustado utilizando PCR.

```{r}
y_p <- predict(modelo_pcr, newdata = testing_x, ncomp=75)
RSS <- (testing_y - y_p)^2
error_pcr <- mean(RSS$Y)
```

A continuación, ajustamos el modelo obtenido con PCR utilizando la muestra de entrenamiento completa. En la figura \ref{fig:coeficientesPCR} podemos ver cómo varían los coeficientes del modelo ajustado reconstruidos para las variables originales (las bandas de frecuencia). Acá se puede apreciar que, si bien no hay una relación directa, en las zonas de frecuencias donde hay mayor variabilidad para la amplitud (figura 2) encontramos coeficientes con valores que se destacan en valor absoluto.

```{r, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:coeficientesPCR}Coeficientes del modelo de PCR para cada banda de frecuencia."}
modelo_pcr_final <- pcr(formula= Y ~ .,data = training, scale. = TRUE, ncomp = which.min(modelo_pcr_tbl$MSE))
coefs <- as.matrix(coef(modelo_pcr_final))

coeficientes_PCR <- tibble(coeficiente = seq(100,400,1),
                           valor = coefs)

coeficientes_PCR %>% ggplot(aes(x = coeficiente,
                                y = valor)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
  geom_line(alpha = .5) +
  geom_point() +
  labs(x = "Frecuencia", y = "Coeficiente")
```

Para evaluar el modelo elegido, estimamos el error de predicción sobre el set que reservamos para testeo (`r nrow(testing)` observaciones) y el resultado obtenido es `r round(error_pcr, digits=3)`.

Una visualización interesante para diagnosticar los supuestos del modelo es graficar los residuos vs. los valores ajustados (figura \ref{fig:residuos}). Si bien en la figura se observa que los residuos para valores ajustados más pequeños son menores, esta diferencia es pequeña y no se ve ninguna estructura clara para los residuos a nivel general (como, por ejemplo, que la variabilidad fuera altamente dependiente de los valores ajustados).

```{r, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "\\label{fig:residuos}Residuos vs. valores ajustados para el modelo PCR."}
residuos_PCR <- tibble(ajustados = modelo_pcr_final$fitted.values[,,which.min(modelo_pcr_tbl$MSE)],
                       residuos = modelo_pcr_final$residuals[,,which.min(modelo_pcr_tbl$MSE)])

residuos_PCR %>% ggplot(aes(x = ajustados,
                            y = residuos)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
  geom_point() +
  labs(x = "Valores ajustados", y = "Residuos")
```

Por último, vamos a observar el QQ-plot de los residuos del modelo ajustado (figura \ref{fig:qqplot}). Al igual que en la figura anterior, no se ve ninguna desviación sistemática ya que en general las observaciones se encuentran bastante alineadas.

```{r qqplot, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 3, fig.cap = "\\label{fig:qqplot}QQ-plot para el modelo PCR."}

ggplot(residuos_PCR, aes(sample = residuos)) +
  stat_qq() +
  stat_qq_line() +
  labs(x = "Cuantiles teóricos", y = "Residuos de la muestra")  
```

## Conclusión

A modo de cierre, proponemos al modelo de PCR (utilizando `r which.min(modelo_pcr_tbl$MSE)` componentes) como el mejor candidato para predecir el contenido de $SiO_2$ a partir de los resultados de un análisis espectrográfico. Esta decisión se basa en que, según nuestro análisis, es el que presenta el menor valor de MSE. Además, el análisis de los residuos no evidenció ninguna desviación sistemática de los supuestos de modelo.
