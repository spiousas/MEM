---
title: "Taller de Análisis de datos - Problema 1"
author: "Jésica Charaf e Ignacio Spiousas"
date: "6 de noviembre de 2023"
output:
  pdf_document:
    extra_dependencies: ["float"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.pos = "H", 
                      out.extra = "")
pacman::p_load(tidyverse, here, glmnet, tidymodels, pls, patchwork, broom, knitr)
theme_set(theme_bw(base_size = 10))
```

# Problema 1-4

Los siguientes datos corresponden a un trabajo para determinar la composición de un conjunto de vasijas de vidrio de un yacimiento arqueológico. Como el análisis espectrométrico es más barato que el análisis químico, se procuró calibrar el primero para que reemplace al segundo. Con este objetivo se tomó una muestra de $n=180$ vasijas, a las que se realizó una espectrometria de rayos X sobre 1920 frecuencias, y también un análisis de laboratorio para determinar el contenido de 13 compuestos químicos, a saber:

$$Na_2O, \; MgO, \; Al_2O_3, \; SiO_2, \; P_2O_5, \; SO_3, \; Cl, \; K_2O, \; CaO, \; MnO, \; Fe_2O_3, \; BaO \; y \; PbO$$

Cada fila del archivo `Vessel_X` es el espectro de una vasija, limitado a las frecuencias $100$ a $400$, pues las demás tienen valores casi nulos. O sea, para cada $i=1,...,n, x(i,j (j=1,..,301))$ es la energía correspondiente a la frecuencia $j$ (en realidad la frecuencia es j+99, pero podemos dejar eso de lado).

Cada fila del archivo `Vessel_Y` tiene los contenidos de los 13 compuestos en esa vasija. Vamos a comparar distintos métodos para predecir el compuesto 4 ($P_2O_5$).

Para familiarizarse con los datos, grafique en función de la frecuencia las medias y varianzas de X, y también algunos espectros (o sea, $x(i,j)$ en función de $j$ para algunos $i$). Aplique los métodos que le parecen adecuados para este problema, y encuentre el que muestra menor error de predicción.

Para el estimador que mejor funciona:

-   Grafique los coeficientes (pendientes) en función de la frecuencia.

-   Haga el clásico gráfico de residuos vs. ajustados.

-   Si ve algo llamativo (outliers, residuos con estructura) tome las medidas correctivas que le parezcan adecuadas.

# Resolución

## Análisis exploratorio

Lo primero que vamos a hacer es a graficar el contenido de `Vessel_X.txt`, es decir, la energía por banda de frecuencia de cada una de las $150$ vasijas. Esto puede verse en líneas continuas de colores en la Figura 1 junto con el promedio en línea sólida negra. En la figura pareciera indicarse que las diferencias entre vasijas ocurren a determinadas frecuencias (en las que la amplitud es distinta de cero y hay más diferencia entre las mediciones individuales) y, por lo tanto, resulta esperable que la información contenida en esas bandas de frecuencias sea la que más aporte a la determinación del contenido de $P_2O_5$ (aunque bajo condiciones particulares podría no ser el caso).

```{r data_loading, fig.align="center", fig.height = 2.5, fig.width = 4, fig.cap = "An amazing plot"}
data_x <- read_delim(here("taller_de_datos/entrega1/data/Vessel_X.txt"),
                     name_repair = "unique",
                     col_names = FALSE,
                     col_types = cols())

data_y <- read_delim(here("taller_de_datos/entrega1/data/Vessel_Y.txt"),
                     name_repair = "unique",
                     col_names = FALSE,
                     col_types = cols()) %>%
  select(X4) %>%
  rename(Y = X4)
```

```{r fig_inicial, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "Energía en función de las frecuencias. Cada línea de color representa una vasija mientras que la línea negra representa al promedio de las 150 vasijas."}
data_x_long <- data_x %>% 
  mutate(sample = factor(row_number())) %>%
  pivot_longer(cols = 1:last_col(1)) %>%
  rename(X = name) %>%
  mutate(X = parse_number(X) + 99) 

summ_data_x <- data_x_long %>%
  group_by(X) %>%
  summarise(m_value = mean(value),
            sem_value = sd(value)/sqrt(n()))

data_x_long %>%
  ggplot(aes(x = X, y = value)) +
  geom_line(aes(color = sample), alpha = .1) +
  geom_line(data = summ_data_x, aes(x = X, y = m_value), linewidth = 1) +
  labs(x = "Frecuencia", y = "Energía") +
  scale_color_viridis_d() +
  theme_bw() +
  theme(legend.position = "none")
```

Para explorar esta ídea un poco más allá podemos ver en la Figura 2 el error estándar de la media en función de la banda de frecuencia. En esta figura vemos cuantificada la intuición que generamos en la Figura 1 de que, efectivamente la variabilidad en las mediciones se concentra en unas pocas bandas de frecuencia.

```{r fig_sem, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "Error estándar en función de las frecuencias."}
summ_data_x %>%
  ggplot(aes(x = X, y = sem_value)) +
  geom_line(linewidth = 1) +
  labs(x = "Frecuencia", y = "SEM") +
  theme_bw()
```

Luego, lo que queremos ver es como se distribuye la cantidad de $P_20_5$ en las muestras, para ver si esto tiene algún patrón. En la Figura 3 podemos ver el histograma y la densidad estimada para esta magnitud. En la misma se ve que no pareciera haber valores atípicos y que la distribución es unimodal y con una cola pesada a la izquierda (hacia valores más bajos). Esta asimetría podría llegar a influir en el supuesto no normalidad de los residuos del modelos a ajustar, más adelante lo evaluaremos.

```{r histograma_y, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "Histograma y estimación de la densidad de la cantidad de P205 en las muestras."}
data_y %>%
  ggplot(aes(x = Y)) +
  geom_histogram(aes(y = after_stat(..density..)), 
                 fill = "steelblue", alpha = 0.5, bins = 30) +
  geom_density(color = "steelblue", linewidth = 1.5) +
  theme_bw() +
  labs(x = "Contenido de P2O5", y = "Densidad") +
  theme(legend.position = "none")
```

Finalmente, y a modo exploratorio, vamos a calcular el coeficiente de correlación entre la energía de cada banda de frecuencia y la cantidad de $P_20_5$. De esta forma queremos seguir indagando sobre qué bandas de frecuencia deberían ser más importantes en el modelo de predicción. En la Figura 4 puede verse el valor absoluto del coeficiente de correlación de Pearson en función de la banda de frecuencia. Retomaremos los resultados de esta figura luego de ajustar un modelo.

```{r correlaciones, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "Energía en función de las frecuencias. Cada línea de color representa una vasija mientras que la línea negra representa al promedio de las 150 vasijas."}
data_xy <- data_x %>%
  bind_cols(data_y)

cor_coef <- rep(NA, 301)
for (i in 1:301) {
  cor_coef[i] <- cor(data_xy[,i], data_xy$Y)
}

data_cor  <- tibble(X = unique(data_x_long$X),
                    r = cor_coef)

data_cor %>%
  ggplot(aes(x = X, y = abs(r))) +
  geom_line(linewidth = 1) +
  labs(x = "Frecuencia", y = "|r|") +
  theme_bw()

```

## Creación de un modelo predictivo

Como lo que queremos hacer es entrenar un modelo predictivo, la métrica que vamos a utilizar para evaluarlo es el error cuadrático medio (MSE^[Del inglés *Mean Squared Error*.]) calculado a partir de una muestra de *testeo*. Para esto vamos a dividir los datos en dos partes, dejando dos tercios de los datos (120 vasijas) en el set de entrenamiento o *training* y un tercio de los datos (60 vasijas) en el set de validación o *testing*. Para evitar que haya una representación desigual de cantidad de $P_20_5$ en las muestras de entrenamiento y validación, vamos a hacer esta división estratíficada^[Como se trata de una variable numérica, la función estratifica la separación a partir de los cuartiles.] utilizando la función `initial_split` del paquete `tidymodels`. 

Vamos a considerar dos familias de modelos para resolver este problema. Primero exploraremos los modelos lineales con regularización (Ridge, Lasso o Elastic Net) utilizando el paquete `glmnet`. Luego exploraremos modelos basados en regresión de componentes principales (PCR^[Del inglés *Principal Components Regression*.]) utilizando el paquete `pls`.

```{r train_test}
set.seed(1234)
split <- initial_split(data_xy, strata = Y, prop = 2/3)
training <- training(split)
training_x <- training(split) %>% select(-Y)
training_y <- training(split) %>% select(Y)
testing <- testing(split)
testing_x <- testing(split) %>% select(-Y)
testing_y <- testing(split) %>% select(Y)
```

### Modelos lineales con regularización

El primer modelo que vamos a ajsutar es un modelo lineal con regularización de Lasso ($\alpha=1$ en `glmnet`). Para esto vamos a utilizar el set de datos de entrenamiento, y para encontrar el mejor $\lambda$ utilizaremos como criterio el MSE y una validación cruzada con 10 *folds*.

```{r}
set.seed(123)
cvfit <- cvfit <- cv.glmnet(as.matrix(training_x), as.matrix(training_y), type.measure = "mse", nfolds = 10, alpha = 1)
tidied <- tidy(cvfit)

myCoefs <- coef(cvfit, s="lambda.min");

myResults <- tibble(
  Componente  = myCoefs@Dimnames[[1]][ which(myCoefs != 0 ) ], #intercept included
  Coeficiente = myCoefs              [ which(myCoefs != 0 ) ]  #intercept included
)
```


Para la regresión con regularización Lasso, el lambda que minimiza el MSE es `r tidied$lambda[which.min(tidied$estimate)]`, con un valor de MSE de `r tidied$estimate[which.min(tidied$estimate)]`. 

En la Figura XXX podemos ver que la mayoría de las componentes no nulas del modelo corresponden con variables con alta correlación con Y. Esto es meramente exploratorio ya que para la selección de variable también resulta relevante que tan correlacionadas están las variables entre sí.

```{r componentes, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "MSE para un modelos glmnet en función de alpha (de Ridge a Lasso) para el mejor lambda obtenido a partir de cross-validation con 10 folds. El panel b muestra un zoom para valores de alpha de 0.5 a 1"}
data_cor %>%
  ggplot(aes(x = X, y = abs(r))) +
  geom_vline(xintercept = parse_number(myResults[2:37,]$Componente)+99, color = "red", linewidth = 2, alpha = .5)+
  geom_line(linewidth = 1) +
  labs(x = "Frecuencia", y = "|r|") +
  theme_bw()

```
#### Buscando los mejores parámetros $\lambda$ y $\alpha$

Un posible paso siguiente es el de, además de buscar el mejor $\lambda$, también hacer una búsqueda en una grilla del parámetro $\alpha$. Este parámetro es el responsable de convertir el modelo de Ridge ($\alpha = 0$) a Lasso ($\alpha = 1$) pasando por Elastic Net ($\alpha = 0.5$). Haremos la búsqueda para una grilla de valores intermedios entre $0$ y $1$ con paso de $0.01$.

```{r glmnet, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "MSE para un modelos glmnet en función de alpha (de Ridge a Lasso) para el mejor lambda obtenido a partir de cross-validation con 10 folds. El panel b muestra un zoom para valores de alpha de 0.5 a 1"}
alphas <- seq(0,1,.01)

errors <- rep(NA, length(alphas))
SEs <- rep(NA, length(alphas))
lambdas <- rep(NA, length(alphas))
nzeros<- rep(NA, length(alphas))

for (i in 1:length(alphas)) {
  set.seed(123)
  cvfit <- cv.glmnet(as.matrix(training_x), as.matrix(training_y), type.measure = "mse", nfolds = 10, alpha = alphas[i])
  tidied <- tidy(cvfit)
  errors[i] <-tidied$estimate[which.min(tidied$estimate)]
  SEs[i] <- tidied$std.error[which.min(tidied$estimate)]
  lambdas[i] <- tidied$lambda[which.min(tidied$estimate)]
  nzeros[i] <- tidied$nzero[which.min(tidied$estimate)]
}

results <- tibble(alphas, errors, SEs)

p1 <- results %>%
  ggplot(aes(x = alphas,
             y = errors)) +
  geom_line(linewidth = 1) +
  labs(x = "Alpha", y = "MSE", subtitle = "MSE en función de alpha") +
  geom_ribbon(aes(ymin = errors-SEs, ymax = errors+SEs), alpha = .3) +
  theme_bw()

p2 <- results %>%
  ggplot(aes(x = alphas,
             y = errors)) +
  geom_line(linewidth = 1) +
  geom_ribbon(aes(ymin = errors-SEs, ymax = errors+SEs), alpha = .3) +
  labs(x = "Alpha", y = "MSE", subtitle = "Zoom de alpha 0.5 a 1") +
  xlim(c(0.5, 1)) +
  ylim(c(0.4, .9)) +
  theme_bw()

p1 + p2 + plot_annotation(tag_levels = 'a')
```

Puede verse que el MSE disminuye monotonamente con el $\alpha$, llegando a un mínimo de `r round(min(errors), digits = 3)` para $\alpha=1$. Es decir, la regresión regularización Lasso es la más conveniente. Para este valor de $\alpha$ el mínimo error se obtuvo para un $\lambda$ de `r round(lambdas[which.min(errors)], digits = 2)`, con un número de componentes no nulas igual a `r nzeros[which.min(errors)]`.

## Regresión de componentes principales

Otro enfoque que exploramos para abordar el problema es el de reducción de la dimensión. Consideramos el método PCR que consiste en ajustar un modelo de regresión lineal utilizando como variables predictoras un sobconjunto de las componentes obtenidas a partir del análisis de componentes principales (PCA^[Del inglés *Principal Components Analysis*.]). De esta manera, se reduce la cantidad de variables predictoras del modelo.

Para implementar este método utilizamos la función `pcr` de la librería `pls`. Esta función calcula las componentes principales y ajusta el modelo de regresión lineal con la cantidad de componentes que se desee. Para elegir la cantidad de componentes usamos *Cross-Validation* sobre la muestra de entrenamiento, separando en $10$ folds y buscando el número que minimice el error de predicción. En la figura XX se muestra un gráfico con los resultados del MSE obtenido por CV en función de la cantidad de componentes.

```{r PCR, warning = FALSE}
#pcr
set.seed(1234)
modelo_pcr <- pcr(formula= Y ~ .,data = training, scale. = TRUE, validation = "CV")
modelo_pcr_CV <- MSEP(modelo_pcr, estimate= "CV")
cv_min_pcr <- min(modelo_pcr_CV$val)
```

```{r PCR_plot, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 6, fig.cap = "Energía en función de las frecuencias. Cada línea de color representa una vasija mientras que la línea negra representa al promedio de las 150 vasijas."}

modelo_PCR <- tibble(componentes = 1:length(modelo_pcr_CV$val),
                     MSE = modelo_pcr_CV$val[1:length(modelo_pcr_CV$val)])
                                             
p1 <- modelo_PCR  %>% ggplot(aes(x = componentes,
                                 y = MSE)) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = which.min(modelo_PCR$MSE), color = "red", linetype = "dashed") +
  labs(x = "Número de componentes", y = "MSE", subtitle = "Todas las componentes")+
  theme(plot.subtitle=element_text(hjust=0.5))

p2 <- modelo_PCR  %>% ggplot(aes(x = componentes,
                                 y = MSE)) +
  geom_line(linewidth = 1) +
  xlim(c(60, 90)) +
  ylim(c(.3, .4)) +
  geom_vline(xintercept = which.min(modelo_PCR$MSE), color = "red", linetype = "dashed") +
  labs(x = "Número de componentes", y = "MSE", subtitle = "Zoom de 60 a 90 componentes") +
  theme(plot.subtitle=element_text(hjust=0.5))

p1 + p2 + plot_annotation(tag_levels = 'a')
  
```

El óptimo se encuentra en `r which.min(modelo_PCR$MSE)` componentes y el valor obtenido para el error de predicción por CV sobre la muestra de entrenamiento es `r round(modelo_PCR$MSE[which.min(modelo_PCR$MSE)], digits = 3)`.

## Comparación de la performance de los modelos predictivos

## Métricas con el set de testeo

# Conclusiones

