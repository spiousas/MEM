---
title: "Taller de Análisis de datos - Problema de clasificación 1"
author: "Jésica Charaf e Ignacio Spiousas"
date: "12 de diciembre de 2023"
output:
  pdf_document:
    extra_dependencies: ["float"]
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.pos = "H", 
                      out.extra = "")
pacman::p_load(tidyverse, here, FNN, pls, patchwork, broom, knitr, GGally, janitor, rsample, randomForest,glmnet, neuralnet)
theme_set(theme_bw(base_size = 10))

doParallel::registerDoParallel()
```

# Problema de clasificación 1

Estos datos son los resultados de análisis químicos de vinos provenientes de la misma región de Italia pero de 3 distintos cultivos. Cada una de las 178 filas contiene el número del cultivo seguido por los valores de 13 mediciones.

Aplique los métodos de clasificación que le parezcan convenientes y compare sus performances.

Los datos están en http://archive.ics.uci.edu/ml/datasets/Wine

# Resolución

## Análisis exploratorio

```{r, warning=FALSE}
vinos <- read_csv(here("taller_de_datos/entrega3/data/wine.data"),
                  col_names = c("Cultivo", "Alcohol", "Malic acid", "Ash", "Alcalinity of ash",
                                "Magnesium", "Total phenols", "Flavanoids", "Nonflavanoid phenols",
                                "Proanthocyanins", "Color intensity", "Hue", "OD280/OD315 of diluted wines",
                                "Proline"),
                  col_types = cols()) %>%
  clean_names()
```

Los datos contienen 178 observaciones donde la primera variable indica el tipo de cultivo (1, 2 o 3) y las siguientes 13 variables corresponden a mediciones de: Alcohol, *Malicacid*, *Ash*, *Alcalinity_of_ash*, *Magnesium*, *Total_phenols*, *Flavanoids*, *Nonflavanoid_phenols*, *Proanthocyanins*, *Color_intensity*, *Hue*, *0D280_0D315_of_diluted_wines* y *Proline*.

Lo primero que vamos a ver es cómo se distribuyen las clases, es decir, cuántos datos pertenecientes a cada cultivo tenemos (figura \ref{fig:clases}).

```{r, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 3, fig.cap = "\\label{fig:clases}Cantidad de datos pertenecientes a cada clase (cultivo) en el dataset a utilizar."}
vinos %>%
  ggplot(aes(x = cultivo)) +
  geom_bar(fill = "steelblue") +
  labs(x = "Cultivo",
       y = "Cuenta")
    
```

Podemos ver que no contamos con grandes desbalances de clase. Se tienen 59 observaciones correspondientes al cultivo 1, 71 del cultivo 2 y 48 del cultivo 3.

Para seguir, en la figura \ref{fig:boxplots} se observan los boxplots y violin plots de las distintas variables según la clase de cultivo.

```{r, warning = FALSE, fig.align="center", fig.height = 7, fig.width = 8, fig.cap = "\\label{fig:boxplots}Boxplots y violin plots de las 13 variables según el tipo de cultivo."}
vinos %>% 
  mutate(cultivo = as.factor(cultivo)) %>%
  pivot_longer(cols = -cultivo,
                       names_to = "Variable",
                       values_to = "Valor") %>%
  ggplot(aes(x = cultivo,
             y = Valor,
             color = cultivo,
             fill = cultivo)) +
  geom_violin(alpha = 0.2) +
  geom_boxplot(width = .2, alpha = .2) +
  labs(x = NULL, y = NULL) +
  scale_color_brewer(palette = "Dark2") + 
  scale_fill_brewer(palette = "Dark2") + 
  facet_wrap(~Variable, scales="free_y") +
  theme(legend.position = "top",
        strip.background = element_rect(fill="white", colour = NA))
```

Allí podemos ver que hay algunas variables que presentan una clara separación por tipo de cultivo y pueden ser relevantes en la clasificación, tales como *alcohol*, *total_phenois*, *flavanoids* y *color_intensity*. A modo de ejemplo, en el caso de la variable *alcohol* vemos que las mediciones son superiores en el cultivo 1, siguiendo el cultivo 3 y luego el 2. Por otra parte, tenemos variables como *ash* y *magnesium* que parecen diferenciarse menos a través de los grupos. Y por último, se observan casos de mediciones como *hue* y *proline* que se distinguen en uno de los cultivos en comparación con los otros dos. Por ejemplo, vemos que las mediciones de *hue* son menores en el cultivo 3, mientras que los otros dos cultivos son más díficiles de diferenciar entre sí a simple vista.

## Elección de los modelos de clasificación

El objetivo del trabajo consiste en explorar diferentes métodos de clasificación para determinar el tipo de cultivo y comparar sus desempeños. Para esto, vamos a considerar los enfoques de K vecinos cercanos, Random Forest, Regresión logística (para modelos multinomiales) y Redes neuronales.

Para analizar los distintos métodos de clasificación, separamos la
muestra en un set de entrenamiento (dos tercios de los datos) y un set
de testeo (un tercio de los datos) de forma estratificada según el
cultivo, utilizando la función `initial_split` de *{rsample}*.

```{r}
# Dividimos el dataset y generamos los folds
set.seed(1234)
split <- initial_split(vinos, 
                       strata = cultivo, 
                       prop = 2/3)
training <- training(split)
testing <- testing(split)

# Los folds de CV
v_cv <- 10
folds<- vfold_cv(training, 
                 v = v_cv,
                 strata = cultivo)
```

La métrica que vamos a utilizar para evaluar los distintos modelos es el *accuracy* ya que los datos
no presentan desbalances de clases marcados ni creemos que haya alguno de los errores que debamos favorecer por sobre el otro.

### K vecinos cercanos

El primer modelo que vamos a ajustar es el de K vecinos cercanos. Para
esto consideraremos una grilla de valores de $k$ (cantidad de vecinos) entre
1 y 20. Para evaluar cuál es la cantidad de vecinos más conveniente
realizamos validación cruzada separando la muestra de entrenamiento en
10 folds estratificando según la clase. Estos *folds* son generados
utilizando la función `vfold_cv` del paquete *{rsample}*.

Como el método de KNN puede verse afectado por variaciones de escala, en cada paso de validación cruzada estandarizamos los datos del subconjunto que se utiliza como entrenamiento y, con esa misma transformación, escalamos los datos del subconjunto sobre el cual se predice.

```{r}
Ks <- 1:20
metricas_knn <- tibble(K = numeric(),
                   Accuracy = numeric())

for (k in Ks) { # Loop en k
  err <- c()
  for (j in 1:v_cv) { # Cross-validation
    
    # Los folds
    fold  <- folds$splits[[j]]
    train <- analysis(fold)
    test  <- assessment(fold)
    
    X_train <- train %>% select(-cultivo)
    Y_train <- train %>% select(cultivo)
    
    X_test <- test %>% select(-cultivo)
    Y_test <- test %>% select(cultivo)
    
    X_train_scaled <- scale(X_train)
    X_test_scaled  <- as_tibble(scale(X_test, 
                                      center = attr(X_train_scaled, "scaled:center"), 
                                      scale = attr(X_train_scaled, "scaled:scale")))
    X_train_scaled <- as_tibble(X_train_scaled)
    
    pred <- knn(train = X_train_scaled, 
                test = X_test_scaled, 
                cl = Y_train %>% pull(cultivo), 
                k = k, 
                prob = TRUE)
    
    err <- append(err, mean(pred == Y_test %>% pull(cultivo)))
  }
  
  metricas_knn <- metricas_knn %>% bind_rows(tibble(K = k, Accuracy = mean(err)))
}
```

```{r, warning=FALSE, fig.height = 3, fig.width = 5, fig.align="center", fig.cap = "\\label{fig:KNN}Accuracy en función de la cantidad de vecinos cercanos."}
metricas_knn %>%
  ggplot(aes(x = K,
             y = Accuracy)) +
  geom_point(size = 2) +
  scale_color_brewer(palette = "Dark2", name = "Semilla") +
  labs(title = "Vecinos cercanos") +
  geom_line(linewidth = 2, alpha = 0.5) +
  theme_bw()
```

Como puede verse en la figura \ref{fig:KNN}, el máximo de Accuracy para los modelos de KNN es de `r round(max(metricas_knn$Accuracy), digits = 2)` para `r which.max(metricas_knn$Accuracy)` vecinos.

### Random Forest

La siguiente alternativa que vamos a considerar es un modelo basado en ensambles
de árboles conocido como Random Forest. En este caso también utilizaremos validación 
cruzada para hallar la combinación de parámetros que maximice el Accuracy, considerando los mismos folds que en K vecinos cercanos pero sin estandarizar los datos. Los 
hiperparámetros que vamos a optimizar en el modelo de Random Forest son: el número de variables 
que se consideran en cada split del árbol aleatorio (`mtry`); y el número mínimo 
de observaciones requeridas para que una hoja se bifurque (`min_n`). 

Vamos a calcular el Accuracy para una grilla de 160 filas, con $1 \leq$`mtry`$\leq 10$ y
$5 \leq$`min_n`$\leq 20$.

```{r}
Ks <- 1:20
metricas_rf <- tibble(mtry = numeric(),
                   min_n = numeric(),
                   Accuracy = numeric())

rf_grid <- expand_grid(
  mtry = seq(1,10),
  min_n = seq(5,20))

set.seed(123)
for (i in 1:nrow(rf_grid)) { # Loop en k
  acc <- c()
  for (j in 1:v_cv) { # Cross-validation
    
    # Los folds
    fold  <- folds$splits[[j]]
    train <- analysis(fold)
    test  <- assessment(fold)

    # Entreno con training
    rf <- randomForest(as_factor(cultivo) ~ ., 
                       data     = train, 
                       mtry     = rf_grid[i,] %>% pull(mtry),
                       maxnodes = rf_grid[i,] %>% pull(min_n),
                       ntree    = 500)
    
    # Predigo con testing
    yhat_rf <- predict(rf, 
                       newdata = test)
    
    acc <- append(acc, mean(yhat_rf == test %>% pull(cultivo)))
  }
  
  metricas_rf <- metricas_rf %>% bind_rows(tibble(mtry = rf_grid[i,] %>% pull(mtry), 
                                            min_n = rf_grid[i,] %>% pull(min_n), 
                                            Accuracy = mean(acc)))
}
```

```{r, warning=FALSE, fig.height = 4, fig.width = 6, fig.align="center", fig.cap = "\\label{fig:RF}Accuracy en función de mtry y minn para Random Forest."}
metricas_rf %>%
  ggplot(aes(x = min_n,
             y = Accuracy,
             color = as.factor(mtry))) +
  geom_point(size = 2) +
  labs(title = "Random forest") +
  geom_line(linewidth = 2, alpha = 0.5) +
  theme(legend.position = "bottom") 
```

Como puede verse en la figura \ref{fig:RF}, el máximo valor de accuracy vale `r round(max(metricas_rf$Accuracy), digits = 3)` para m_try igual a `r metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(mtry)` y min_n igual a `r metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(min_n)`.

### Regresión logística

Para continuar, otro enfoque que exploraremos es el de regresión logística para modelos multinomiales. Vamos a ajustar una familia de modelos con regularización Lasso utilizando el paquete glmnet. 

Para esto, armamos una grilla de valores de $\lambda$ tomando 100 valores entre $10^{-3}$ y $10^0$. Para cada valor de $\lambda$, evaluamos el Accuracy realizando validación cruzada de la misma forma que en los métodos previos.

```{r, warning=FALSE}
lambdas <- 10 ^ seq(0, -3, length = 50)
metricas_glm <- tibble(lambda = numeric(),
                      Accuracy = numeric())

for (l in 1:length(lambdas)){
  acc <- rep(0,10)
  
  for (j in 1:v_cv) { # Cross-validation
    # Los folds
    fold  <- folds$splits[[j]]
    train <- analysis(fold)
    test  <- assessment(fold)
    
    fit <- glmnet(x = as.matrix(train %>% select(-cultivo)), 
                  y = as.matrix(train %>% select(cultivo)), 
                  family = "multinomial", 
                  type.multinomial = "grouped",
                  lambda = lambdas[l])
    pred <- predict(fit, 
                    newx = as.matrix(test %>% select(-cultivo)), 
                    s = lambdas[l], 
                    type = 'class')
    acc[j] <- mean(pred == test %>% pull(cultivo))
  }
  
  metricas_glm <- metricas_glm %>% bind_rows(tibble(lambda = lambdas[l], 
                                                    Accuracy = mean(acc)))
  
}
```

```{r, warning=FALSE, fig.height = 3, fig.width = 5, fig.align="center", fig.cap = "\\label{fig:glm}Accuracy en función del valor de lambda."}
metricas_glm %>%
  ggplot(aes(x = lambda,
             y = Accuracy)) +
  geom_point(size = 2) +
  labs(title = "Regresión logística multinomial") +
  geom_line(linewidth = 2, alpha = 0.5) +
  scale_x_continuous(trans='log10') +
  theme(legend.position = "bottom") 
```

En la figura \ref{fig:glm} observamos los resultados del Accuracy en función de $\lambda$ y vemos que el máximo se alcanza en $\lambda$ igual a `r round(lambdas[which.max(metricas_glm$Accuracy)], digits = 3)` con un valor de `r round(max(metricas_glm$Accuracy), digits = 3)`.

### Redes neuronales

Finalmente, vamos a considerar un modelo de redes neuronales para predecir el cultivo. Por simplicidad el modelo contiene una sola capa intermedia y por medio de validación cruzada vamos a determinar cuántas neuronas conviene incluir en esta capa. Para esto, consideramos una grilla de valores entre 1 y 10 para la cantidad de neuronas y buscamos el número que maximice el Accuracy.

En este caso, al igual que en K vecinos cercanos, estandarizamos los datos en cada paso de validación cruzada ya que obtuvimos mejores resultados de esta manera.

```{r}
Ns <- 1:10
metricas_dnn <- tibble(n = numeric(),
                       Accuracy = numeric())

set.seed(123)
for (n in Ns) { # Loop en n
  acc <- c()
  for (j in 1:v_cv) { # Cross-validation
    
    # Los folds
    fold  <- folds$splits[[j]]
    train <- analysis(fold) %>% mutate(cultivo = as.factor(cultivo))
    test  <- assessment(fold) %>% mutate(cultivo = as.factor(cultivo))
    
    X_train <- train %>% select(-cultivo)
    Y_train <- train %>% select(cultivo)
    
    X_test <- test %>% select(-cultivo)
    Y_test <- test %>% select(cultivo)
    
    X_train_scaled <- scale(X_train)
    test_scaled <- as_tibble(scale(X_test, 
                                   center = attr(X_train_scaled, "scaled:center"), 
                                   scale = attr(X_train_scaled, "scaled:scale"))) %>%
      bind_cols(Y_test)
    train_scaled <- as_tibble(X_train_scaled) %>%
      bind_cols(Y_train)
    
    model = neuralnet(
      cultivo ~ .,
      data = train_scaled,
      hidden = c(Ns[n]),
      linear.output = FALSE
    )
    
    pred <- predict(model, test_scaled)
    labels <- c("1", "2", "3")
    check <- as.numeric(test_scaled$cultivo) == max.col(pred)
    
    acc <- append(acc, (sum(check)/nrow(test_scaled)))
  }
  
  metricas_dnn <- metricas_dnn %>% bind_rows(tibble(n = Ns[n], Accuracy = mean(acc)))
}
```

```{r, warning=FALSE, fig.height = 3, fig.width = 5, fig.align="center", fig.cap = "\\label{fig:DNN}Accuracy en función de la cantidad de neuronas en la capa intermedia."}
metricas_dnn %>%
  ggplot(aes(x = n,
             y = Accuracy)) +
  geom_point(size = 2) +
  scale_color_brewer(palette = "Dark2", name = "Semilla") +
  labs(title = "Redes neuronales", x = "Cantidad de neuronas en la capa intermedia") +
  geom_line(linewidth = 2, alpha = 0.5) +
  theme_bw()
```

En la figura \ref{fig:DNN} observamos los resultados del Accuracy en función de la cantidad de neuronas de la capa intermedia y vemos que el máximo se alcanza utilizando `r metricas_dnn$n[which.max(metricas_dnn$Accuracy)]` neuronas con un valor de `r round(max(metricas_dnn$Accuracy), digits = 3)`.

Además, en la figura \ref{fig:DNN_esquema} podemos ver una representación del modelo que elegimos mediante validación cruzada, ajustado con todos los datos del set de entrenamiento.

```{r, warning=FALSE, fig.height = 6, fig.width = 10, fig.align="center", fig.cap = "\\label{fig:DNN_esquema}Representación esquemática de la red neuronal ajustada a partir de la selección de parámetros con validación cruzada."}
train<- training %>% mutate(cultivo = as.factor(cultivo))
X_train <- train %>% select(-cultivo)
Y_train <- train %>% select(cultivo)
    
train_scaled <- scale(X_train) %>%
      bind_cols(Y_train)

set.seed(12)    
model = neuralnet(
      cultivo ~ .,
      data = train_scaled,
      hidden = c(metricas_dnn$n[which.max(metricas_dnn$Accuracy)]),
      linear.output = FALSE
    )

plot(model, rep = "best")
```

## Comparación de los métodos en un conjunto de testeo

A partir del análisis realizado, vemos que los mejores modelos de cada familia estudiada tienen un comportamiento muy similar basándonos en el Accuracy obtenido por validación cruzada.

A continuación vamos a comparar el desempeño de los modelos seleccionados para cada método ajustándolos con todo el set de entrenamiento y evaluándolos en el conjunto que reservamos para testeo. Calculamos el Accuracy en cada caso y los resultados obtenidos son los siguientes:


```{r, warning=FALSE}
X_training <- training %>% select(-cultivo)
Y_training <- training %>% select(cultivo)
    
X_testing <- testing %>% select(-cultivo)
Y_testing <- testing %>% select(cultivo)
    
X_training_scaled <- scale(X_training)
X_testing_scaled  <- as_tibble(scale(X_testing, 
                                  center = attr(X_training_scaled, "scaled:center"), 
                                  scale = attr(X_training_scaled, "scaled:scale")))
X_training_scaled <- as_tibble(X_training_scaled)
    
   
#vecinos cercanos
pred_knn<- knn(train = X_training_scaled, 
                test = X_testing_scaled, 
                cl = Y_training %>% pull(cultivo), 
                k = which.max(metricas_knn$Accuracy), 
                prob = TRUE)

acc_knn<-mean(pred_knn == Y_testing %>% pull(cultivo))

```

- `r round(acc_knn, digits = 3)` para el modelo de KNN utilizando `r which.max(metricas_knn$Accuracy)` vecinos cercanos.

```{r, warning=FALSE}
#random forest
set.seed(12)
ajuste_rf <- randomForest(as_factor(cultivo) ~ ., 
                       data     = training, 
                       mtry     = metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(mtry),
                       maxnodes = metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(min_n),
                       ntree    = 500)

pred_rf <- predict(ajuste_rf, newdata = testing)
acc_rf<-mean(pred_rf == testing %>% pull(cultivo))

```


- `r round(acc_rf, digits = 3)` en el modelo seleccionado para Random Forest con m_try igual a `r metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(mtry)` y min_n igual a `r metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(min_n)`.

```{r, warning=FALSE}
#glm
ajuste_glm <- glmnet(x = as.matrix(training %>% select(-cultivo)), 
                  y = as.matrix(training %>% select(cultivo)), 
                  family = "multinomial", 
                  type.multinomial = "grouped",
                  lambda = lambdas[which.max(metricas_glm$Accuracy)])

pred_glm <- predict(ajuste_glm, 
                newx = as.matrix(testing %>% select(-cultivo)), 
                s = lambdas[which.max(metricas_glm$Accuracy)], 
                    type = 'class')
acc_glm <- mean(pred_glm == testing %>% pull(cultivo))
```


- `r round(acc_glm, digits = 3)` en el caso del modelo de regresión logística con regularización Lasso con un $\lambda$ igual a `r round(lambdas[which.max(metricas_glm$Accuracy)], digits = 3)`.

```{r, warning=FALSE}
#red neuronal
train<- training %>% mutate(cultivo = as.factor(cultivo))
test<-testing %>% mutate(cultivo = as.factor(cultivo))

X_train <- train %>% select(-cultivo)
Y_train <- train %>% select(cultivo)

X_test <- test %>% select(-cultivo)
Y_test <- test %>% select(cultivo)

X_train_scaled <- scale(X_train)
test_scaled <- as_tibble(scale(X_test, 
                               center = attr(X_train_scaled, "scaled:center"), 
                               scale = attr(X_train_scaled, "scaled:scale"))) %>%
  bind_cols(Y_test)
train_scaled <- as_tibble(X_train_scaled) %>%
  bind_cols(Y_train)

set.seed(12)
model = neuralnet(
  cultivo ~ .,
  data = train_scaled,
  hidden = c(metricas_dnn$n[which.max(metricas_dnn$Accuracy)]),
  linear.output = FALSE
)

pred <- predict(model, test_scaled)
labels <- c("1", "2", "3")
check <- as.numeric(test_scaled$cultivo) == max.col(pred)

acc_nn <- (sum(check)/nrow(test_scaled))

```


- `r round(acc_nn, digits = 3)` para la red neuronal con una capa que contiene `r metricas_dnn$n[which.max(metricas_dnn$Accuracy)]` neuronas.

Además, para tener una mayor comprensión de cómo clasifican los diferentes métodos realizamos tablas donde se pueden ver las clases predichas vs. las clases verdaderas.

```{r, warning=FALSE}
tabla_knn <-table(Y_testing %>% pull(cultivo),pred_knn)
tabla_rf <-table(Y_testing %>% pull(cultivo),pred_rf)
tabla_glm <-table(Y_testing %>% pull(cultivo),pred_glm)
tabla_nn <- table(as.numeric(test_scaled$cultivo),max.col(pred))
```

```{=tex}
\begin{table}[h]
\begin{center}
\begin{tabular}{| c | c | c  c  c || c | c | c  c  c |}
\hline
\multicolumn{5}{| c|| }{ \textbf{KNN}} & \multicolumn{5}{| c| }{\textbf{Random Forest}}\\ \hline
& & \multicolumn{3}{ c|| }{Predichos}& & & \multicolumn{3}{ c| }{Predichos} \\ \hline
& & 1 & 2 & 3 & & & 1 & 2 & 3\\ \hline
Verdaderos & 1 & `r tabla_knn[1,1]` & `r tabla_knn[1,2]` & `r tabla_knn[1,3]` &
Verdaderos & 1 & `r tabla_rf[1,1]` & `r tabla_rf[1,2]` & `r tabla_rf[1,3]`\\
& 2 & `r tabla_knn[2,1]` & `r tabla_knn[2,2]` & `r tabla_knn[2,3]` &
& 2 & `r tabla_rf[2,1]` & `r tabla_rf[2,2]` & `r tabla_rf[2,3]` \\
& 3 & `r tabla_knn[3,1]` & `r tabla_knn[3,2]` & `r tabla_knn[3,3]` &
& 3 & `r tabla_rf[3,1]` & `r tabla_rf[3,2]` & `r tabla_rf[3,3]`\\
 \hline
\end{tabular}

\vspace{5mm}

\begin{tabular}{| c | c | c  c  c || c | c | c  c  c |}
\hline
\multicolumn{5}{| c|| }{ \textbf{Regresión logística}} & \multicolumn{5}{| c| }{\textbf{Red neuronal}}\\ \hline
& & \multicolumn{3}{ c|| }{Predichos}& & & \multicolumn{3}{ c| }{Predichos} \\ \hline
& & 1 & 2 & 3 & & & 1 & 2 & 3\\ \hline
Verdaderos & 1 & `r tabla_glm[1,1]` & `r tabla_glm[1,2]` & `r tabla_glm[1,3]` &
Verdaderos & 1 & `r tabla_nn[1,1]` & `r tabla_nn[1,2]` & `r tabla_nn[1,3]`\\
& 2 & `r tabla_glm[2,1]` & `r tabla_glm[2,2]` & `r tabla_glm[2,3]` &
& 2 & `r tabla_nn[2,1]` & `r tabla_nn[2,2]` & `r tabla_nn[2,3]` \\
& 3 & `r tabla_glm[3,1]` & `r tabla_glm[3,2]` & `r tabla_glm[3,3]` &
& 3 & `r tabla_nn[3,1]` & `r tabla_nn[3,2]` & `r tabla_nn[3,3]`\\
 \hline
\end{tabular}
\caption{Tablas de clases predichas vs. clases verdaderas.}
\end{center}

\end{table}

```

## Conclusiones

Como puede verse en la sección anterior, todos los modelos propuestos tienen una excelente performance clasificando el cultivo de una muestra de vino a partir de las 13 variables. Si tuviéramos que elegir un modelo candidato, elegiríamos Regrasión Logística Multinomial o Random Forest ya que resultan modelos más interpretables.