---
title: "Taller de Análisis de datos - Problema de clasificación 1"
author: "Jésica Charaf e Ignacio Spiousas"
date: "12 de diciembre de 2023"
output:
  pdf_document:
    extra_dependencies: ["float"]
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.pos = "H", 
                      out.extra = "")
pacman::p_load(tidyverse, here, FNN, pls, patchwork, broom, knitr, GGally, janitor, rsample, randomForest,glmnet)
theme_set(theme_bw(base_size = 10))

doParallel::registerDoParallel()
```

# Problema de clasificación 1

Estos datos son los resultados de análisis químicos de vinos provenientes de la misma región de Italia pero de 3 distintos cultivos. Cada una de las 178 filas contiene el número del cultivo seguido por los valores de 13 mediciones.

Aplique los métodos de clasificación que le parezcan convenientes y compare sus performances.

Los datos están en http://archive.ics.uci.edu/ml/datasets/Wine

# Resolución

## Análisis exploratorio

```{r, warning=FALSE}
vinos <- read_csv("wine.data",
                  col_names = c("Cultivo", "Alcohol", "Malic acid", "Ash", "Alcalinity of ash",
                                "Magnesium", "Total phenols", "Flavanoids", "Nonflavanoid phenols",
                                "Proanthocyanins", "Color intensity", "Hue", "OD280/OD315 of diluted wines",
                                "Proline"),
                  col_types = cols()) %>%
  clean_names()
```

Los datos contienen 178 observaciones donde la primera variable indica el tipo de cultivo (1, 2 o 3) y las siguientes 13 variables corresponden a mediciones de: Alcohol, Malicacid, Ash, Alcalinity_of_ash, Magnesium, Total_phenols, Flavanoids, Nonflavanoid_phenols, Proanthocyanins, Color_intensity, Hue, 0D280_0D315_of_diluted_wines y Proline.

Lo primero que vamos a ver es cómo se distribuyen las clases, es decir, cuántos datos pertenecientes a cada cultivo tenemos (figura \ref{fig:clases}).

```{r, warning = FALSE, fig.align="center", fig.height = 3, fig.width = 3, fig.cap = "\\label{fig:clases}Cantidad de datos pertenecientes a cada clase (cultivo) en el dataset a utilizar."}
vinos %>%
  ggplot(aes(x = cultivo)) +
  geom_bar(fill = "steelblue") +
  labs(x = "Cultivo",
       y = "Cuenta")
    
```

Podemos ver que no contamos con grandes desbalances de clase. Se tienen 59 observaciones correspondientes al cultivo 1, 71 del cultivo 2 y 48 del cultivo 3.

NOTA: Acá poner un poco más de exploración de la relación de los cultivos con las variables.

## Comparación de métodos de clasificación

El objetivo del trabajo consiste en explorar diferentes métodos de clasificación para determinar el tipo de cultivo y comparar sus desempeños. Para eso, vamos a considerar los enfoques de K vecinos cercanos, Random Forest y Regresión logística para modelos multinomiales.

Para analizar los distintos métodos de clasificación, separamos la
muestra en un set de entrenamiento (dos tercios de los datos) y un set
de testeo (un tercio de los datos) de forma estratificada según el
cultivo, utilizando la función `initial_split` de *{rsample}*.

```{r}
# Dividimos el dataset y generamos los folds
set.seed(1234)
split <- initial_split(vinos, 
                       strata = cultivo, 
                       prop = 2/3)
training <- training(split)
testing <- testing(split)

X_train <- training %>% select(-cultivo)
Y_train <- training %>% select(cultivo)

X_test <- testing %>% select(-cultivo)
Y_test <- testing %>% select(cultivo)

X_train_scaled = scale(X_train)
X_test_scaled = scale(X_test, 
                      center = attr(X_train_scaled, "scaled:center"), 
                      scale = attr(X_train_scaled, "scaled:scale"))
```

La métrica que vamos a utilizar para evaluar el modelo es el *accuracy* ya que los datos
no presentan desbalances de clases marcados ni creemos que haya alguno de los errores 
(tipo I y tipo II) que debamos favorecer por sobre el otro.

### K vecinos cercanos

El primer modelo que vamos a ajustar es el de K vecinos cercanos. Para
esto consideramos una grilla de valores de $k$ (cantidad de vecinos) entre
1 y 20. Para evaluar cuál es la cantidad de vecinos más conveniente
realizamos validación cruzada separando la muestra de entrenamiento en
10 folds estratificando según la clase. Estos *folds* son generados
utilizando la función `vfold_cv` del paquete *{rsample}*.

Para utilizar el modelo de KNN primero vamos a escalar los datos.

```{r, warning=FALSE}
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)

set.seed(123)
v_cv <- 10
folds_sc <- vfold_cv(training, 
                     v = v_cv,
                     strata = cultivo)
```

```{r, warning=FALSE, fig.height = 3, fig.width = 5, fig.align="center", fig.cap = "\\label{fig:KNN}Accuracy en función de la cantidad de vecinos cercanos."}
Ks <- 1:20
metricas_knn <- tibble(K = numeric(),
                   Accuracy = numeric())

for (k in Ks) { # Loop en k
  err <- c()
  for (j in 1:v_cv) { # Cross-validation
    
    # Los folds
    fold  <- folds_sc$splits[[j]]
    train <- analysis(fold)
    test  <- assessment(fold)
    
    X_train <- train %>% select(-cultivo)
    Y_train <- train %>% select(cultivo)
    
    X_test <- test %>% select(-cultivo)
    Y_test <- test %>% select(cultivo)
    
    X_train_scaled <- scale(X_train)
    X_test_scaled  <- as_tibble(scale(X_test, 
                                      center = attr(X_train_scaled, "scaled:center"), 
                                      scale = attr(X_train_scaled, "scaled:scale")))
    X_train_scaled <- as_tibble(X_train_scaled)
    
    pred <- knn(train = X_train_scaled, 
                test = X_test_scaled, 
                cl = Y_train %>% pull(cultivo), 
                k = k, 
                prob = TRUE)
    
    err <- append(err, mean(pred == Y_test %>% pull(cultivo)))
  }
  
  metricas_knn <- metricas_knn %>% bind_rows(tibble(K = k, Accuracy = mean(err)))
}

metricas_knn %>%
  ggplot(aes(x = K,
             y = Accuracy)) +
  geom_point(size = 2) +
  scale_color_brewer(palette = "Dark2", name = "Semilla") +
  labs(title = "Vecinos cercanos") +
  geom_line(linewidth = 2, alpha = 0.5) +
  theme_bw()
```

Como puede verse en la figura \ref{fig:KNN}, el máximo de Accuracy para los modelos de KNN es de `r round(max(metricas_knn$Accuracy), digits = 2)` para `r which.max(metricas_knn$Accuracy)` vecinos.

### Random Forest

La siguiente alternativa que vamos a considerar es un modelo basado en ensambles
de árboles conocido como Random Forest. En este caso también utilizaremos validación 
cruzada para hallar la combinación de parámetros que maximice el Accuracy. Los 
hiperparámetros a optimizar en un modelo de Random Forest son: el número de variables 
que se consideran en cada split del árbol aleatorio (`mtry`); y el número mínimo 
de observaciones requeridas para que una hoja se bifurque (`min_n`). 

Vamos a calcular el Accuracy para una grilla de 160 filas, con $1 \leq$`mtry`$\leq 10$ y
$5 \leq$`min_n`$\leq 20$. Al igual que en KNN, utilizaremos los datos estandarizados
(aunque en este caso no debería afectar a los resultados).

```{r, warning=FALSE, fig.height = 4, fig.width = 6, fig.align="center", fig.cap = "\\label{fig:RF}Accuracy en función de mtry y minn para Random Forest."}
Ks <- 1:20
metricas_rf <- tibble(mtry = numeric(),
                   min_n = numeric(),
                   Accuracy = numeric())

rf_grid <- expand_grid(
  mtry = seq(1,10),
  min_n = seq(5,20))

for (i in 1:nrow(rf_grid)) { # Loop en k
  acc <- c()
  for (j in 1:v_cv) { # Cross-validation
    
    # Los folds
    fold  <- folds_sc$splits[[j]]
    train <- analysis(fold)
    test  <- assessment(fold)
    
    # Entreno con training
    rf <- randomForest(as_factor(cultivo) ~ ., 
                       data     = train, 
                       mtry     = rf_grid[i,] %>% pull(mtry),
                       maxnodes = rf_grid[i,] %>% pull(min_n),
                       ntree    = 500)
    
    # Predigo con testing
    yhat_rf <- predict(rf, 
                       newdata = test)
    
    acc <- append(acc, mean(yhat_rf == test %>% pull(cultivo)))
  }
  
  metricas_rf <- metricas_rf %>% bind_rows(tibble(mtry = rf_grid[i,] %>% pull(mtry), 
                                            min_n = rf_grid[i,] %>% pull(min_n), 
                                            Accuracy = mean(acc)))
}

metricas_rf %>%
  ggplot(aes(x = min_n,
             y = Accuracy,
             color = as.factor(mtry))) +
  geom_point(size = 2) +
  labs(title = "Random forest") +
  geom_line(linewidth = 2, alpha = 0.5) +
  theme(legend.position = "bottom") 
```

Como puede verse en la figura \ref{fig:RF}, el máximo valor de accuracy vale `r round(max(metricas_rf$Accuracy), digits = 3)` para m_try igual a `r metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(mtry)` y min_n igual a `r metricas_rf[which.max(metricas_rf$Accuracy),] %>% pull(min_n)`.

### Regresión logística

El último enfoque que vamos a considerar es el de regresión logística para modelos multinomiales. Ajustaremos una familia de modelos con regularización Lasso utilizando el paquete glmnet. 

Para esto, armamos una grilla de valores de $\lambda$ tomando 100 valores entre $10^{-3}$ y $10^0$. Para cada valor de $\lambda$, evaluamos el Accuracy realizando validación cruzada de la misma forma que en los otros métodos.

```{r, warning=FALSE}
lambdas<-10 ^ seq(0, -3, length = 100)
metricas<-rep(NA,length(lambdas))
for (l in 1:length(lambdas)){
  acc <- rep(0,10)
  for (j in 1:v_cv) { # Cross-validation
    # Los folds
    fold  <- folds_sc$splits[[j]]
    train <- analysis(fold)
    test  <- assessment(fold)
    fit = glmnet(as.matrix(train[,-14]),as.matrix(train[,14]) , family = "multinomial", 
                 type.multinomial = "grouped")
    pred<-predict(fit, newx=as.matrix(test[,-14]), s=lambdas[l], type = 'class')
    acc[j] <- mean(pred == test %>% pull(cultivo))
  }
  metricas[l]<-mean(acc)
}
```

```{r, warning=FALSE, fig.height = 3, fig.width = 5, fig.align="center", fig.cap = "\\label{fig:glm}Accuracy en función del valor de lambda."}
plot(lambdas,metricas,xlab="Lambda", ylab="Accuracy", type="b")

```

En la figura xx observamos los resultados del Accuracy en función de $\lambda$ y vemos que el máximo se alcanza en $\lambda$ igual a `r round(lambdas[which.max(metricas)], digits = 2)` con un valor de `r round(max(metricas), digits = 2)`.

## Evaluación del modelo elegido

